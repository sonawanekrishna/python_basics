{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonawanekrishna/python_basics/blob/main/groq_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i5xj0LQJVKk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7816b0cc-ae69-42d4-c5ad-751ae4a6c72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.32.0\n"
          ]
        }
      ],
      "source": [
        "pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # To access the keys\n",
        "from google.colab import userdata  # Secure storage of API keys in Colab\n",
        "groq_api_key = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "LyBJaJkCWUSy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=groq_api_key,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content) # reading from json file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4f8axaDVaUS",
        "outputId": "1568f15b-2f50-4c61-fb75-1b39b704f0c7",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models are crucial in today's technology landscape, and their importance cannot be overstated. Here are some reasons why:\n",
            "\n",
            "1. **Improved User Experience**: Fast language models enable quick and efficient processing of natural language, allowing users to interact with devices, applications, and services in a more seamless and intuitive way. This leads to a better overall user experience, as users can get answers, complete tasks, and access information more rapidly.\n",
            "2. **Enhanced Productivity**: With fast language models, tasks such as text analysis, sentiment analysis, and language translation can be performed much faster, freeing up time for more strategic and creative work. This can lead to increased productivity and efficiency in various industries, including customer service, marketing, and research.\n",
            "3. **Real-time Applications**: Fast language models are essential for real-time applications, such as:\n",
            "\t* Virtual assistants (e.g., Siri, Alexa, Google Assistant)\n",
            "\t* Chatbots\n",
            "\t* Live language translation\n",
            "\t* Sentiment analysis for social media monitoring\n",
            "\t* Real-time text summarization\n",
            "4. **Competitive Advantage**: Companies that leverage fast language models can gain a competitive advantage by:\n",
            "\t* Providing faster and more accurate customer support\n",
            "\t* Offering more efficient and effective language translation services\n",
            "\t* Enhancing their marketing and sales efforts through AI-powered content generation and analysis\n",
            "\t* Improving their overall customer experience and satisfaction\n",
            "5. **Research and Development**: Fast language models can accelerate research and development in various fields, including:\n",
            "\t* Natural Language Processing (NLP)\n",
            "\t* Machine Learning (ML)\n",
            "\t* Artificial Intelligence (AI)\n",
            "\t* Cognitive Computing\n",
            "\t* Human-Computer Interaction (HCI)\n",
            "6. **Accessibility and Inclusion**: Fast language models can help bridge the language gap and improve accessibility for people with disabilities, such as:\n",
            "\t* Real-time language translation for people with hearing or speech impairments\n",
            "\t* Text-to-speech and speech-to-text systems for people with visual or auditory disabilities\n",
            "7. **Scalability and Cost-Effectiveness**: Fast language models can handle large volumes of data and scale to meet the needs of growing organizations, making them a cost-effective solution for companies with increasing language processing demands.\n",
            "8. **Improved Accuracy**: Fast language models can process large amounts of data, which can lead to improved accuracy and reduced errors in language understanding and generation tasks.\n",
            "9. **Enabling New Applications**: Fast language models can enable new applications and use cases, such as:\n",
            "\t* Voice-controlled interfaces\n",
            "\t* Intelligent writing assistants\n",
            "\t* Automated content generation\n",
            "\t* Language-based games and entertainment\n",
            "10. **Future-Proofing**: Investing in fast language models can help organizations future-proof their technology infrastructure, as the demand for efficient and effective language processing continues to grow.\n",
            "\n",
            "In summary, fast language models are essential for improving user experience, enhancing productivity, and driving innovation in various industries. Their importance will only continue to grow as technology advances and the need for efficient language processing increases.\n"
          ]
        }
      ]
    }
  ]
}